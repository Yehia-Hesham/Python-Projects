{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774c5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date \n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216cec9f",
   "metadata": {},
   "source": [
    "### Scrap the books (name, price, rate) for each category and put them into a CSV & Excel file\n",
    "### https://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eef10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request('GET',\"https://books.toscrape.com/\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee0c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### original attempt, scrapped as it didn't account for multiple pages per category ###\n",
    "#==============================================================================================#\n",
    "# #def scrape_categories():\n",
    "    \n",
    "# all_categories = soup.find('div',attrs = { 'class':'side_categories'}).find('ul').find_all('a')\n",
    "# categories_names = []\n",
    "# categories_links = []\n",
    "# categories = []\n",
    "\n",
    "# for category in all_categories:\n",
    "#     categories_names.append(category.get_text().strip())\n",
    "#     categories_links.append(category.get('href'))\n",
    "\n",
    "# for index in range(len(all_categories)):\n",
    "#     categories.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "\n",
    "# #return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc4db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt 2 \n",
    "def scrape_pages():\n",
    "    \n",
    "    all_categories = soup.find('div',attrs = { 'class':'side_categories'}).find('ul').find_all('a')\n",
    "    \n",
    "    categories_names = []       #all main categories \n",
    "    categories_main_pages = []  #index/main page of each category '../../index.html'\n",
    "    categories_links = []       #all links/directories for all categories' main page\n",
    "    all_pages = []   #all pages' data (category,link)\n",
    "    \n",
    "        #save each category's name & link to lists 'names' and 'links'\n",
    "    for category in all_categories:\n",
    "        categories_names.append(category.get_text().strip())\n",
    "        categories_links.append(category.get('href'))\n",
    "    \n",
    "        #loop by number of categories\n",
    "    for index in range(len(all_categories)):\n",
    "        \n",
    "            #save category's main page data to list 'main_pages'\n",
    "        categories_main_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "        \n",
    "            #detect 'next' button in category's main page\n",
    "        category_response = requests.request('GET',categories_main_pages[index][1])\n",
    "        category_soup = BeautifulSoup(category_response.content,'html.parser')\n",
    "        next_btn = category_soup.find('li',attrs={'class':'current'})\n",
    "        \n",
    "            #if there is no \"next\" button (category has single page), add main page data to list 'all_pages' \n",
    "        if next_btn == None:   \n",
    "            all_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "            \n",
    "        else:\n",
    "                #detect how many pages are there for the category \n",
    "            count = int(next_btn.get_text().split()[-1])\n",
    "            \n",
    "                #loop by number of pages and add each page's data to list 'all_pages'\n",
    "            for i in range(1,count+1):\n",
    "                all_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index][:-10]+f'page-{i}.html'))\n",
    "                \n",
    "    return all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726fc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(all_pages):\n",
    "    \n",
    "    book_entries = [] #each book's data (category, name, price, rating)\n",
    "    \n",
    "        #loop by each page in , find each book's information and save it in list 'books' \n",
    "    for category in range(50,len(all_pages)):     #skips pages with category 'Books' (from 0 to 49) as it contains all other books\n",
    "        \n",
    "        response = requests.request('GET',all_pages[category][1])\n",
    "        soup = BeautifulSoup(response.content,'html.parser')\n",
    "        books = soup.find_all('article',attrs={'class':'product_pod'}) #finds all the books in the page and puts them in a list \n",
    "        \n",
    "            #loop by number of books found in page\n",
    "        for book in range(len(books)):\n",
    "            \n",
    "                #collect book info\n",
    "            cat = all_pages[category][0]\n",
    "            name = books[book].find('h3').find('a').get('title')\n",
    "            price = books[book].find('p',attrs={'class':'price_color'}).get_text()[1:] + \" £\"\n",
    "            rating = books[book].find('p').get('class')[1] + \" star(s)\"\n",
    "            \n",
    "                #append book info to list 'book_entries'\n",
    "            book_entries.append({\"cat\": cat, \"name\": name, \"price\":price, \"rating\": rating})\n",
    "            \n",
    "    return book_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3356c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_the_website():\n",
    "    \n",
    "    print(\"scrapping website pages, please wait...\")\n",
    "    pages = scrape_pages()\n",
    "    \n",
    "    print(\"scraping website pages complete, scrapping book data...\")\n",
    "    book_data = scrape_books(pages)\n",
    "    \n",
    "    print(\"scraping book data complete, writing file...\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    with open('books to scrape web scrapping.csv','w') as f:\n",
    "        writer = csv.DictWriter(f,fieldnames = ['cat','name','price','rating'])\n",
    "        writer.writeheader()\n",
    "        for i in range(len(book_data)):\n",
    "            writer.writerow(book_data[i])     \n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e69446c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping website pages, please wait...\n",
      "scraping website pages complete, scrapping book data...\n",
      "scraping book data complete, writing file...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "scrape_the_website()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b006074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('books to scrape web scrapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bfc1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Childrens</td>\n",
       "      <td>The White Cat and the Monk: A Retelling of the...</td>\n",
       "      <td>58.08 �</td>\n",
       "      <td>Four star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Poetry</td>\n",
       "      <td>Twenty Love Poems and a Song of Despair</td>\n",
       "      <td>30.95 �</td>\n",
       "      <td>Four star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Default</td>\n",
       "      <td>Maude (1883-1993):She Grew Up with the country</td>\n",
       "      <td>18.02 �</td>\n",
       "      <td>Two star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Default</td>\n",
       "      <td>Every Last Word</td>\n",
       "      <td>46.47 �</td>\n",
       "      <td>Three star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>31.63 �</td>\n",
       "      <td>Four star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Default</td>\n",
       "      <td>Modern Day Fables</td>\n",
       "      <td>47.44 �</td>\n",
       "      <td>Two star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Womens Fiction</td>\n",
       "      <td>Something Borrowed (Darcy &amp; Rachel #1)</td>\n",
       "      <td>48.96 �</td>\n",
       "      <td>Five star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Childrens</td>\n",
       "      <td>Maybe Something Beautiful: How Art Transformed...</td>\n",
       "      <td>22.54 �</td>\n",
       "      <td>One star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Atlas Shrugged</td>\n",
       "      <td>26.58 �</td>\n",
       "      <td>Five star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Music</td>\n",
       "      <td>Love Is a Mix Tape (Music #1)</td>\n",
       "      <td>18.03 �</td>\n",
       "      <td>One star(s)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                               name  \\\n",
       "294       Childrens  The White Cat and the Monk: A Retelling of the...   \n",
       "830          Poetry            Twenty Love Poems and a Song of Despair   \n",
       "456         Default     Maude (1883-1993):She Grew Up with the country   \n",
       "498         Default                                    Every Last Word   \n",
       "719         Fantasy  Harry Potter and the Order of the Phoenix (Har...   \n",
       "518         Default                                  Modern Day Fables   \n",
       "221  Womens Fiction             Something Borrowed (Darcy & Rachel #1)   \n",
       "306       Childrens  Maybe Something Beautiful: How Art Transformed...   \n",
       "273         Fiction                                     Atlas Shrugged   \n",
       "440           Music                      Love Is a Mix Tape (Music #1)   \n",
       "\n",
       "       price         rating  \n",
       "294  58.08 �   Four star(s)  \n",
       "830  30.95 �   Four star(s)  \n",
       "456  18.02 �    Two star(s)  \n",
       "498  46.47 �  Three star(s)  \n",
       "719  31.63 �   Four star(s)  \n",
       "518  47.44 �    Two star(s)  \n",
       "221  48.96 �   Five star(s)  \n",
       "306  22.54 �    One star(s)  \n",
       "273  26.58 �   Five star(s)  \n",
       "440  18.03 �    One star(s)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df61094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)    #1000 Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b6282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
